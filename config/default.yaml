agent:
  policy_learning_rate: 1e-3
  critic_learning_rate: 1e-3
  encoder_learning_rate: 1e-3
  n_simulations: ${simulation.n}
  action_scaling:
    - 1.0
    - 1.0
    - 1.0
  exploration:
    stddev: 1.0
    autotune_scale: 0.5
    success_rate_estimator_speed: 0.1

  policy_model_arch:
  critic_model_arch:
  encoder_model_arch:

buffer:
  size: 10000

simulation:
  n: 40
  guis:
    -

procedure:
  episode_length: 10
  batch_size: 256
  updates_per_sample: 8
  log_freq: 1

experiment:
  n_episodes: 100000
  policy_every: 2
  critic_every: 1
  forward_every: 1
  evaluate_every: 20
  record_episode_every: 1000
  save_every: 100
  final_recording: True


hydra:
  run:
    dir: ../experiments/${now:%Y-%m-%d}/${now:%H-%M-%S}_${hydra.job.override_dirname}
  sweep:
    dir: ../experiments/${now:%Y-%m-%d}/${now:%H-%M-%S}/
    subdir: job${hydra.job.num}_${hydra.job.override_dirname}
  job:
    config:
      # configuration for the ${hydra.job.override_dirname} runtime variable
      override_dirname:
        kv_sep: '.'
        item_sep: '__'
        exclude_keys: []
